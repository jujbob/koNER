{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch-crf in /home/work/.local/lib/python3.6/site-packages (0.7.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule, XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 500\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "BERT_MODEL = 'xlm-roberta-base'\n",
    "TOKENIZER = transformers.XLMRobertaTokenizer.from_pretrained(BERT_MODEL)\n",
    "#TRAIN_FILE = \"./data/train_data_annotated_BIOES_v3.txt\"\n",
    "#VALID_FILE = \"./data/e\"\n",
    "TRAIN_FILE = \"./data/xa\"\n",
    "VALID_FILE = \"./data/c\"\n",
    "#TRAIN_FILE = \"/home/ktlim/code/TTtagger/corpus/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    "#VALID_FILE = \"/home/ktlim/code/TTtagger/corpus/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-test.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=0\n",
    "ID, FORM, LEMMA, UPOS, XPOS, FEATS, HEAD, DEPREL, DEPS, MISC = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(word):\n",
    "    return re.sub(r\"\\d\", \"0\", word).lower()\n",
    "\n",
    "\n",
    "def strong_normalize(word):\n",
    "    w = ftfy.fix_text(word.lower())\n",
    "    w = re.sub(r\".+@.+\", \"*EMAIL*\", w)\n",
    "    w = re.sub(r\"@\\w+\", \"*AT*\", w)\n",
    "    w = re.sub(r\"(https?://|www\\.).*\", \"*url*\", w)\n",
    "    w = re.sub(r\"([^\\d])\\1{2,}\", r\"\\1\\1\", w)\n",
    "    w = re.sub(r\"([^\\d][^\\d])\\1{2,}\", r\"\\1\\1\", w)\n",
    "    w = re.sub(r\"``\", '\"', w)\n",
    "    w = re.sub(r\"''\", '\"', w)\n",
    "    w = re.sub(r\"\\d\", \"0\", w)\n",
    "    return w\n",
    "\n",
    "\n",
    "def buildVocab(graphs, cutoff=1):\n",
    "    wordsCount = Counter()\n",
    "    charsCount = Counter()\n",
    "    uposCount = Counter()\n",
    "    xposCount = Counter()\n",
    "    relCount = Counter()\n",
    "    featCount = Counter()\n",
    "    langCount = Counter()\n",
    "\n",
    "    for graph in graphs:\n",
    "        wordsCount.update([node.norm for node in graph.nodes[1:]])\n",
    "        for node in graph.nodes[1:]:\n",
    "            charsCount.update(list(node.word))\n",
    "            featCount.update(node.feats_set)\n",
    "            #  charsCount.update(list(node.norm))\n",
    "        uposCount.update([node.upos for node in graph.nodes[1:]])\n",
    "        xposCount.update([node.xupos for node in graph.nodes[1:]])\n",
    "        relCount.update([rel for rel in graph.rels[1:]])\n",
    "        langCount.update([node.lang for node in graph.nodes[1:]])\n",
    "        \n",
    "\n",
    "    wordsCount = Counter({w: i for w, i in wordsCount.items() if i >= cutoff})\n",
    "    print(\"Vocab containing {} words\".format(len(wordsCount)))\n",
    "    print(\"Charset containing {} chars\".format(len(charsCount)))\n",
    "    print(\"UPOS containing {} tags\".format(len(uposCount)), uposCount)\n",
    "    #print(\"XPOS containing {} tags\".format(len(xposCount)), xposCount)\n",
    "    print(\"Rels containing {} tags\".format(len(relCount)), relCount)\n",
    "    print(\"Feats containing {} tags\".format(len(featCount)), featCount)\n",
    "    print(\"lang containing {} tags\".format(len(langCount)), langCount)\n",
    "\n",
    "    ret = {\n",
    "        \"vocab\": list(wordsCount.keys()),\n",
    "        \"wordfreq\": wordsCount,\n",
    "        \"charset\": list(charsCount.keys()),\n",
    "        \"charfreq\": charsCount,\n",
    "        \"upos\": list(uposCount.keys()),\n",
    "        \"xpos\": list(xposCount.keys()),\n",
    "        \"rels\": list(relCount.keys()),\n",
    "        \"feats\": list(featCount.keys()),\n",
    "        \"lang\": list(langCount.keys()),\n",
    "    }\n",
    "\n",
    "    return ret\n",
    "\n",
    "def shuffled_stream(data):\n",
    "    len_data = len(data)\n",
    "    while True:\n",
    "        for d in random.sample(data, len_data):\n",
    "            yield d\n",
    "\n",
    "def shuffled_balanced_stream(data):\n",
    "    for ds in zip(*[shuffled_stream(s) for s in data]):\n",
    "        ds = list(ds)\n",
    "        random.shuffle(ds)\n",
    "        for d in ds:\n",
    "            yield d\n",
    "            \n",
    "            \n",
    "def parse_dict(features):\n",
    "    if features is None or features == \"_\":\n",
    "        return {}\n",
    "\n",
    "    ret = {}\n",
    "    lst = features.split(\"|\")\n",
    "    for l in lst:\n",
    "        k, v = l.split(\"=\")\n",
    "        ret[k] = v\n",
    "    return ret\n",
    "\n",
    "\n",
    "def parse_features(features):\n",
    "    if features is None or features == \"_\":\n",
    "        return set()\n",
    "\n",
    "    return features.lower().split(\"|\")\n",
    "\n",
    "\n",
    "class Word:\n",
    "\n",
    "    def __init__(self, word, upos, lemma=None, xpos=None, feats=None, misc=None, lang=None):\n",
    "        self.word = word\n",
    "        self.norm = normalize(word) #strong_normalize(word)\n",
    "        self.lemma = lemma if lemma else \"_\"\n",
    "        self.upos = upos\n",
    "        self.xpos = xpos if xpos else \"_\"\n",
    "        self.xupos = self.upos + \"|\" + self.xpos\n",
    "        self.feats = feats if feats else \"_\"\n",
    "        self.feats_set = parse_features(self.feats)\n",
    "        self.misc = misc if misc else \"_\"\n",
    "        self.lang = lang if lang else \"_\"\n",
    "\n",
    "    def cleaned(self):\n",
    "        return Word(self.word, \"_\")\n",
    "\n",
    "    def clone(self):\n",
    "        return Word(self.word, self.upos, self.lemma, self.xpos, self.feats, self.misc)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}_{}\".format(self.word, self.upos)\n",
    "\n",
    "\n",
    "class DependencyGraph(object):\n",
    "\n",
    "    def __init__(self, words, tokens=None):\n",
    "        #  Token is a tuple (start, end, form)\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        self.nodes = np.array([Word(\"*root*\", \"*root*\")] + list(words))\n",
    "        self.tokens = tokens\n",
    "        self.heads = np.array([-1] * len(self.nodes))\n",
    "        self.rels = np.array([\"_\"] * len(self.nodes), dtype=object)\n",
    "\n",
    "    def __copy__(self):\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        result.nodes = self.nodes\n",
    "        result.tokens = self.tokens\n",
    "        result.heads = self.heads.copy()\n",
    "        result.rels = self.rels.copy()\n",
    "        return result\n",
    "\n",
    "    def cleaned(self, node_level=True):\n",
    "        if node_level:\n",
    "            return DependencyGraph([node.cleaned() for node in self.nodes[1:]], self.tokens)\n",
    "        else:\n",
    "            return DependencyGraph([node.clone() for node in self.nodes[1:]], self.tokens)\n",
    "\n",
    "    def attach(self, head, tail, rel):\n",
    "        self.heads[tail] = head\n",
    "        self.rels[tail] = rel\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([\"{} ->({})  {} ({})\".format(str(self.nodes[i]), self.rels[i], self.heads[i], self.nodes[self.heads[i]]) for i in range(len(self.nodes))])\n",
    "\n",
    "\n",
    "def read_conll(filename, lang_code=None):\n",
    "    \n",
    "    print(\"read_conll with\", lang_code)\n",
    "    def get_word(columns):\n",
    "        return Word(columns[FORM], columns[UPOS], lemma=columns[LEMMA], xpos=columns[XPOS], feats=columns[FEATS], misc=columns[MISC], lang=lang_code)\n",
    "\n",
    "    def get_graph(graphs, words, tokens, edges):\n",
    "        graph = DependencyGraph(words, tokens)\n",
    "        for (h, d, r) in edges:\n",
    "            graph.attach(h, d, r)\n",
    "        graphs.append(graph)\n",
    "\n",
    "    file = open(filename, \"r\", encoding=\"UTF-8\")\n",
    "\n",
    "    graphs = []\n",
    "    words = []\n",
    "    tokens = []\n",
    "    edges = []\n",
    "\n",
    "    num_sent = 0\n",
    "    sentence_start = False\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            if len(words) > 0:\n",
    "                get_graph(graphs, words, tokens, edges)\n",
    "                words, tokens, edges = [], [], []\n",
    "            break\n",
    "        line = line.rstrip(\"\\r\\n\")\n",
    "\n",
    "        # Handle sentence start boundaries\n",
    "        if not sentence_start:\n",
    "            # Skip comments\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            # Start a new sentence\n",
    "            sentence_start = True\n",
    "        if not line:\n",
    "            sentence_start = False\n",
    "            if len(words) > 0:\n",
    "                if (len(words) < 250):\n",
    "                    get_graph(graphs, words, tokens, edges)\n",
    "                words, tokens, edges = [], [], []\n",
    "                num_sent += 1\n",
    "            continue\n",
    "\n",
    "        # Read next token/word\n",
    "        columns = line.split(\"\\t\")\n",
    "\n",
    "        # Skip empty nodes\n",
    "        if \".\" in columns[ID]:\n",
    "            continue\n",
    "\n",
    "        # Handle multi-word tokens to save word(s)\n",
    "        if \"-\" in columns[ID]:\n",
    "            start, end = map(int, columns[ID].split(\"-\"))\n",
    "            tokens.append((start, end + 1, columns[FORM]))\n",
    "\n",
    "            for _ in range(start, end + 1):\n",
    "                word_line = file.readline().rstrip(\"\\r\\n\")\n",
    "                word_columns = word_line.split(\"\\t\")\n",
    "                words.append(get_word(word_columns))\n",
    "                if word_columns[HEAD].isdigit():\n",
    "                    head = int(word_columns[HEAD])\n",
    "                else:\n",
    "                    head = -1\n",
    "                edges.append((head, int(word_columns[ID]), word_columns[DEPREL].split(\":\")[0]))\n",
    "        # Basic tokens/words\n",
    "        else:\n",
    "            words.append(get_word(columns))\n",
    "            if columns[HEAD].isdigit():\n",
    "                head = int(columns[HEAD])\n",
    "            else:\n",
    "                head = -1\n",
    "            edges.append((head, int(columns[ID]), columns[DEPREL].split(\":\")[0]))\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loader\n",
    "class CoNLLDataset:\n",
    "    def __init__(self, graphs, tokenizer, max_len, fullvocab=None):\n",
    "        self.conll_graphs = graphs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self._fullvocab = fullvocab if fullvocab else buildVocab(self.conll_graphs, cutoff=1)\n",
    "            \n",
    "        self._upos = {p: i for i, p in enumerate(self._fullvocab[\"upos\"])}\n",
    "        self._iupos = self._fullvocab[\"upos\"]\n",
    "        self._xpos = {p: i for i, p in enumerate(self._fullvocab[\"xpos\"])}\n",
    "        self._ixpos = self._fullvocab[\"xpos\"]\n",
    "        self._vocab = {w: i+3 for i, w in enumerate(self._fullvocab[\"vocab\"])}\n",
    "        self._wordfreq = self._fullvocab[\"wordfreq\"]\n",
    "        self._charset = {c: i+3 for i, c in enumerate(self._fullvocab[\"charset\"])}\n",
    "        self._charfreq = self._fullvocab[\"charfreq\"]\n",
    "        self._rels = {r: i for i, r in enumerate(self._fullvocab[\"rels\"])}\n",
    "        self._irels = self._fullvocab[\"rels\"]\n",
    "        self._feats = {f: i for i, f in enumerate(self._fullvocab[\"feats\"])}\n",
    "        self._langs = {r: i+2 for i, r in enumerate(self._fullvocab[\"lang\"])}\n",
    "        self._ilangs = self._fullvocab[\"lang\"]\n",
    "        \n",
    "        #self._posRels = {r: i for i, r in enumerate(self._fullvocab[\"posRel\"])}\n",
    "        #self._iposRels = self._fullvocab[\"posRel\"]\n",
    "        \n",
    "        self._vocab['*pad*'] = 0\n",
    "        self._charset['*pad*'] = 0\n",
    "        self._langs['*pad*'] = 0\n",
    "        \n",
    "        self._vocab['*root*'] = 1\n",
    "        self._charset['*whitespace*'] = 1\n",
    "        \n",
    "        self._vocab['*unknown*'] = 2\n",
    "        self._charset['*unknown*'] = 2\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.conll_graphs)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        graph = self.conll_graphs[item]\n",
    "        word_list = [node.word for node in graph.nodes]\n",
    "        upos_list = [node.upos for node in graph.nodes]\n",
    "        feat_list = [node.feats for node in graph.nodes]\n",
    "        \n",
    "        encoded = self.tokenizer.encode_plus(' '.join(word_list[1:]),\n",
    "                                             None,\n",
    "                                             add_special_tokens=True,\n",
    "                                             max_length = self.max_len,\n",
    "                                             truncation=True,\n",
    "                                             pad_to_max_length = True)\n",
    "        \n",
    "        ids, mask = encoded['input_ids'], encoded['attention_mask']\n",
    "        \n",
    "        bpe_head_mask = [0]; upos_ids = [-1]; feat_ids = [-1] # --> CLS token\n",
    "        \n",
    "        for word, upos, feat in zip(word_list[1:], upos_list[1:], feat_list[1:]):\n",
    "            bpe_len = len(self.tokenizer.tokenize(word))\n",
    "            head_mask = [1] + [0]*(bpe_len-1)\n",
    "            bpe_head_mask.extend(head_mask)\n",
    "            upos_mask = [self._upos.get(upos)] + [-1]*(bpe_len-1)\n",
    "            upos_ids.extend(upos_mask)\n",
    "            feat_mask = [self._feats.get(feat.lower(), 2)] + [-1]*(bpe_len-1)\n",
    "            feat_ids.extend(feat_mask)\n",
    "            \n",
    "            #print(\"head_mask\", head_mask)\n",
    "        \n",
    "        bpe_head_mask.append(0); upos_ids.append(-1); feat_ids.append(-1) # --> END token\n",
    "        bpe_head_mask.extend([0] * (self.max_len - len(bpe_head_mask))) ## --> padding by max_len\n",
    "        upos_ids.extend([-1] * (self.max_len - len(upos_ids))) ## --> padding by max_len\n",
    "        feat_ids.extend([-1] * (self.max_len - len(feat_ids))) ## --> padding by max_len\n",
    "        \n",
    "        return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'bpe_head_mask': torch.tensor(bpe_head_mask, dtype=torch.long),\n",
    "                'upos_ids': torch.tensor(upos_ids, dtype=torch.long),\n",
    "                'feat_ids': torch.tensor(feat_ids, dtype=torch.long)\n",
    "               }\n",
    "    \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(total_pred, total_targ, noNER_idx):\n",
    "    \n",
    "    p = 0 # (retrived SB and real SB) / retrived SB  # The percentage of (the number of correct predictions) / (the number of predction that system predicts as B-SENT)\n",
    "    r = 0\n",
    "    f1= 0\n",
    "    \n",
    "    np_total_pred = np.array(total_pred)\n",
    "    np_total_tag = np.array(total_targ)\n",
    "    \n",
    "    #Get noPad\n",
    "    incidence_nopad = np.where(np_total_tag != -1) ## eliminate paddings\n",
    "    np_total_pred_nopad = np_total_pred[incidence_nopad]\n",
    "    np_total_tag_nopad = np_total_tag[incidence_nopad]\n",
    "    \n",
    "    \n",
    "    #precision\n",
    "    incidence_nopad_sb = np.where(np_total_pred_nopad != noNER_idx)\n",
    "    np_total_pred_nopad_sb = np_total_pred_nopad[incidence_nopad_sb]\n",
    "    np_total_tag_nopad_sb = np_total_tag_nopad[incidence_nopad_sb]\n",
    "    \n",
    "    count_active_tokens_p = len(np_total_pred_nopad_sb)\n",
    "    count_correct_p = np.count_nonzero((np_total_pred_nopad_sb==np_total_tag_nopad_sb) == True)\n",
    "    \n",
    "    '''\n",
    "    np_total_pred_incid = np_total_pred[incidence_p]\n",
    "    print(\"np_total_pred_incid\", np_total_pred_incid)\n",
    "    ids_sb_pred_p = np.where(np_total_pred_incid==1)\n",
    "    np_total_pred_p = np_total_pred_incid[ids_sb_pred_p]\n",
    "    np_total_tag_p = np_total_tag[ids_sb_pred_p]\n",
    "    \n",
    "    print(\"ids_sb_pred_p\", ids_sb_pred_p)\n",
    "    print(\"np_total_pred_p\", np_total_pred_p)\n",
    "    print(\"np_total_tag_p\", np_total_tag_p)\n",
    "    \n",
    "    count_active_tokens_p = len(np_total_pred_p)\n",
    "    count_correct_p = np.count_nonzero((np_total_pred_p==np_total_tag_p) == True)\n",
    "    '''\n",
    "    \n",
    "    print(\"count_correct_p\", count_correct_p)\n",
    "    print(\"count_active_tokens_p\", count_active_tokens_p)\n",
    "    \n",
    "    p = count_correct_p/count_active_tokens_p\n",
    "    print(\"precision:\", p)\n",
    "\n",
    "    \n",
    "    #recall\n",
    "    ids_sb_pred_r = np.where(np_total_tag_nopad != noNER_idx)\n",
    "    np_total_pred_r = np_total_pred_nopad[ids_sb_pred_r]\n",
    "    np_total_tag_r = np_total_tag_nopad[ids_sb_pred_r]\n",
    "    \n",
    "    #print(\"ids_sb_pred_r\", ids_sb_pred_r)\n",
    "    #print(\"np_total_pred_r\", np_total_pred_r)\n",
    "    #print(\"np_total_tag_r\", np_total_tag_r)\n",
    "    \n",
    "    count_active_tokens_r = len(np_total_pred_r)\n",
    "    count_correct_r = np.count_nonzero((np_total_pred_r==np_total_tag_r) == True)\n",
    "    \n",
    "    print(\"count_active_tokens_r\", count_active_tokens_r)\n",
    "    print(\"count_correct_r\", count_correct_r)\n",
    "    \n",
    "    r = count_correct_r/count_active_tokens_r\n",
    "    print(\"recall:\", r)\n",
    "    \n",
    "    \n",
    "    #F1\n",
    "    #f1 = 2*(p*r) / (p+r)\n",
    "    print(\"F1:\", f1)\n",
    "    \n",
    "    #count_active_tokens_recall = np.count_nonzero(np.array(total_targ) > -1)\n",
    "    #print(\"count_active_tokens_recall\", count_active_tokens_recall)\n",
    "    #count_active_tokens_precision = np.count_nonzero(np.array(total_targ) > -1)\n",
    "    \n",
    "    #count_correct = np.count_nonzero((np.array(total_pred)==np.array(total_targ)) == True)\n",
    "    #print(\"count_correct\",count_correct)\n",
    "    #print(\"ACCURACY:\", count_correct/count_active_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaEncoder(nn.Module):\n",
    "    def __init__(self, num_upos, num_feat):\n",
    "        super(XLMRobertaEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size =768\n",
    "        self.xlm_roberta = transformers.XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear = nn.Linear(self.hidden_size, num_upos)\n",
    "        \n",
    "        self.f_dropout = nn.Dropout(0.33)\n",
    "        self.f_linear = nn.Linear(768, num_feat)\n",
    "        \n",
    "        self.crf = CRF(num_tags=num_feat, batch_first=True)\n",
    "        \n",
    "            \n",
    "    def forward(self, ids, mask, targets=None):\n",
    "        o1, o2 = self.xlm_roberta(ids, mask)\n",
    "        \n",
    "        #apool = torch.mean(o1, 1)\n",
    "        #mpool, _ = torch.max(o1, 1)\n",
    "        #cat = torch.cat((apool, mpool), 1)\n",
    "        #bo = self.dropout(cat)\n",
    "        \n",
    "        o1 = self.f_dropout(o1)\n",
    "        p_logits = self.linear(o1)        \n",
    "        f_logits = self.f_linear(o1)   \n",
    "        \n",
    "        \n",
    "        if targets is not None:\n",
    "            log_likelihood, crf_out = self.crf(f_logits, targets), self.crf.decode(f_logits)\n",
    "            return p_logits, f_logits, log_likelihood, crf_out\n",
    "        else:\n",
    "            crf_out = self.crf.decode(f_logits)\n",
    "        \n",
    "        #print(crf_out, crf_out.size)\n",
    "        \n",
    "        \n",
    "        #if tags is not None: # crf training\n",
    "        #    log_likelihood, sequence_of_tags = self.crf(emissions, tags), self.crf.decode(emissions)\n",
    "        #    return log_likelihood, sequence_of_tags\n",
    "        #else: # tag inference\n",
    "        #    sequence_of_tags = self.crf.decode(emissions)\n",
    "        #    return sequence_of_tags, outputs\n",
    "\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_graphs = read_conll(TRAIN_FILE, 'ko')\n",
    "#cv = KFold(n_splits=5, random_state=1, shuffle=False)\n",
    "#for t,v in cv.split(train_graphs):\n",
    "#    train_graph=train_graphs[t]         # Train Set\n",
    "#    valid_graph=train_graphs[v]         # Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_conll with ko\n",
      "Vocab containing 4561 words\n",
      "Charset containing 1027 chars\n",
      "UPOS containing 15 tags Counter({'NOUN': 5257, 'PRT': 3801, 'ADP': 2810, 'VERB': 1691, 'PUNCT': 1550, 'PROPN': 645, 'NUM': 557, 'X': 281, 'DET': 220, 'ADJ': 206, 'PRON': 117, 'SYM': 105, 'ADV': 71, 'INTJ': 8, 'CCONJ': 2})\n",
      "Rels containing 2 tags Counter({'rel': 16630, 'root': 691})\n",
      "Feats containing 49 tags Counter({'o': 13571, 'cvl_s': 385, 'num_b': 330, 'num_e': 330, 'per_s': 239, 'org_s': 172, 'num_i': 161, 'org_i': 151, 'dat_b': 130, 'dat_e': 129, 'loc_s': 121, 'org_e': 116, 'org_b': 114, 'dat_i': 106, 'trm_i': 104, 'cvl_b': 88, 'cvl_e': 88, 'trm_s': 80, 'trm_e': 79, 'trm_b': 78, 'per_b': 78, 'per_e': 77, 'num_s': 62, 'per_i': 61, 'cvl_i': 52, 'dat_s': 50, 'anm_s': 43, 'evt_b': 40, 'evt_e': 40, 'evt_s': 27, 'evt_i': 26, 'loc_b': 20, 'afw_s': 20, 'loc_e': 19, 'tim_b': 19, 'tim_e': 19, 'tim_i': 15, 'afw_i': 14, 'loc_i': 12, 'fld_s': 11, 'afw_b': 9, 'afw_e': 9, 'tim_s': 7, 'plt_s': 6, 'fld_b': 5, 'fld_e': 5, 'mat_s': 1, 'anm_b': 1, 'anm_e': 1})\n",
      "lang containing 1 tags Counter({'ko': 17321})\n",
      "read_conll with ko\n"
     ]
    }
   ],
   "source": [
    "train_graphs = read_conll(TRAIN_FILE, 'ko')\n",
    "train_dataset = CoNLLDataset(graphs=train_graphs, tokenizer=TOKENIZER, max_len=MAX_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, num_workers=4, batch_size=TRAIN_BATCH_SIZE, shuffle=False)\n",
    "valid_graphs = read_conll(VALID_FILE, 'ko')\n",
    "valid_dataset = CoNLLDataset(graphs=valid_graphs, tokenizer=TOKENIZER, max_len=MAX_LEN, fullvocab=train_dataset._fullvocab)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, num_workers=4, batch_size=VALID_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_upos = len(train_dataset._upos)\n",
    "num_feat = len(train_dataset._feats)\n",
    "model = XLMRobertaEncoder(num_upos, num_feat)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "lr = 0.000005\n",
    "optimizer = AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(train_loader, model, optimizer, DEVICE, scheduler=None):\n",
    "    model.train()\n",
    "    \n",
    "    p_total_pred = []\n",
    "    p_total_targ = []\n",
    "    p_total_loss = []\n",
    "    \n",
    "    f_total_pred = []\n",
    "    f_total_targ = []\n",
    "    f_total_loss = []\n",
    "    \n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        p_logits, f_logits, likelihood, crf_out = model(batch['ids'].cuda(), batch['mask'].cuda(), batch['feat_ids'].cuda())\n",
    "        \n",
    "        #UPOS\n",
    "        b,s,l = p_logits.size()\n",
    "        #print(p_logits.view(b*s,l), p_logits.view(b*s,l).size())\n",
    "        #print(batch['upos_ids'].cuda().view(b*s), batch['upos_ids'].cuda().view(b*s).size())\n",
    "        p_loss = loss_fn(p_logits.view(b*s,l), batch['upos_ids'].cuda().view(b*s))\n",
    "        p_total_loss.append(p_loss.item())\n",
    "        p_total_pred.extend(torch.argmax(p_logits.view(b*s,l), 1).cpu().tolist())\n",
    "        p_total_targ.extend(batch['upos_ids'].cuda().view(b*s).cpu().tolist())\n",
    "        \n",
    "        #FEAT\n",
    "        b,s,l = f_logits.size()\n",
    "        f_loss = loss_fn(f_logits.view(b*s,l), batch['feat_ids'].cuda().view(b*s))\n",
    "        f_total_loss.append(f_loss.item())\n",
    "        #f_total_pred.extend(torch.argmax(f_logits.view(b*s,l), 1).cpu().tolist())\n",
    "        \n",
    "        #f_total_pred.extend(crf_out)\n",
    "        f_total_targ.extend(batch['feat_ids'].cuda().view(b*s).cpu().tolist())\n",
    "        \n",
    "        for s in crf_out:\n",
    "            f_total_pred.extend(s)\n",
    "        \n",
    "        loss = p_loss + (-1 * likelihood)\n",
    "        #print(\"crf_out\", crf_out)\n",
    "        #print(\"pred\", torch.argmax(f_logits.view(b*s,l), 1).cpu().tolist())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    count_active_tokens = np.count_nonzero(np.array(p_total_targ) > -1)\n",
    "    count_correct = np.count_nonzero((np.array(p_total_pred)==np.array(p_total_targ)) == True)\n",
    "    print(\"TRAINING POS ACCURACY:\", count_correct/count_active_tokens)\n",
    "    \n",
    "    count_active_tokens = np.count_nonzero(np.array(f_total_targ) > -1)\n",
    "    count_correct = np.count_nonzero((np.array(f_total_pred)==np.array(f_total_targ)) == True)\n",
    "    f1_score(f_total_pred, f_total_targ, train_dataset._feats.get('o', 2))\n",
    "    print(\"TRAINING FEAT ACCURACY:\", count_correct/count_active_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop_fn(dev_loader, model, DEVICE):\n",
    "    model.eval()\n",
    "    \n",
    "    p_total_pred = []\n",
    "    p_total_targ = []\n",
    "    p_total_loss = []\n",
    "    \n",
    "    f_total_pred = []\n",
    "    f_total_targ = []\n",
    "    f_total_loss = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(dev_loader), total=len(dev_loader)):\n",
    "\n",
    "            p_logits, f_logits = model(batch['ids'].cuda(), batch['mask'].cuda())\n",
    "\n",
    "            #UPOS\n",
    "            b,s,l = p_logits.size()\n",
    "            p_loss = loss_fn(p_logits.view(b*s,l), batch['upos_ids'].cuda().view(b*s))\n",
    "            p_total_loss.append(p_loss.item())\n",
    "            p_total_pred.extend(torch.argmax(p_logits.view(b*s,l), 1).cpu().tolist())\n",
    "            p_total_targ.extend(batch['upos_ids'].cuda().view(b*s).cpu().tolist())\n",
    "\n",
    "            #FEAT\n",
    "            b,s,l = f_logits.size()\n",
    "            f_loss = loss_fn(f_logits.view(b*s,l), batch['feat_ids'].cuda().view(b*s))\n",
    "            f_total_loss.append(f_loss.item())\n",
    "            f_total_pred.extend(torch.argmax(f_logits.view(b*s,l), 1).cpu().tolist())\n",
    "            f_total_targ.extend(batch['feat_ids'].cuda().view(b*s).cpu().tolist())\n",
    "\n",
    "            loss = p_loss+f_loss\n",
    "        \n",
    "    count_active_tokens = np.count_nonzero(np.array(p_total_targ) > -1)\n",
    "    count_correct = np.count_nonzero((np.array(p_total_pred)==np.array(p_total_targ)) == True)\n",
    "    print(\"VALIDATION POS ACCURACY:\", count_correct/count_active_tokens)\n",
    "    \n",
    "    count_active_tokens = np.count_nonzero(np.array(f_total_targ) > -1)\n",
    "    count_correct = np.count_nonzero((np.array(f_total_pred)==np.array(f_total_targ)) == True)\n",
    "    f1_score(f_total_pred, f_total_targ, train_dataset._feats.get('o', 2))\n",
    "    print(\"VALIDATION FEAT ACCURACY:\", count_correct/count_active_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset._feats.get('o'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/116 [00:01<02:36,  1.36s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 15.75 GiB total capacity; 9.17 GiB already allocated; 64.56 MiB free; 181.98 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9fca8d114ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#valid_loop_fn(valid_loader, model, DEVICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8910acee47f0>\u001b[0m in \u001b[0;36mtrain_loop_fn\u001b[0;34m(train_loader, model, optimizer, DEVICE, scheduler)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mp_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#UPOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1d6006e4b60c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask, targets)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mo1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlm_roberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#apool = torch.mean(o1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         )\n\u001b[1;32m    764\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 )\n\u001b[1;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    369\u001b[0m     ):\n\u001b[1;32m    370\u001b[0m         self_attention_outputs = self.attention(\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    313\u001b[0m     ):\n\u001b[1;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    317\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 15.75 GiB total capacity; 9.17 GiB already allocated; 64.56 MiB free; 181.98 MiB cached)"
     ]
    }
   ],
   "source": [
    "for idx in range(EPOCHS):\n",
    "    train_loop_fn(train_loader, model, optimizer, DEVICE)\n",
    "    #valid_loop_fn(valid_loader, model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loop_fn(valid_loader, model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.4 on Python 3.6 (CUDA 10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
