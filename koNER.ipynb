{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule, XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 500\n",
    "TRAIN_BATCH_SIZE = 60\n",
    "VALID_BATCH_SIZE = 60\n",
    "EPOCHS = 100\n",
    "BERT_MODEL = 'xlm-roberta-base'\n",
    "TOKENIZER = transformers.XLMRobertaTokenizer.from_pretrained(BERT_MODEL)\n",
    "\n",
    "DATASET = \"MODU21\" #MODU21 #ETRI\n",
    "VALID_FILE = None\n",
    "if DATASET == \"NANVER\":\n",
    "    #TRAIN_FILE = \"./data/bio_group1_test.conllu\"\n",
    "    #VALID_FILE = \"./data/bio_group1_test.conllu\"\n",
    "    TRAIN_FILE = \"./data/train_data.bio.converted\"\n",
    "elif DATASET == \"KLUE\":\n",
    "    TRAIN_FILE = \"./data/klue-ner-v1.1_train.converted\"\n",
    "    VALID_FILE = \"./data/klue-ner-v1.1_dev.converted\"\n",
    "elif DATASET == \"MODU19\":\n",
    "    TRAIN_FILE = \"./data/NXNE2102008030.converted\" #MODU19\n",
    "elif DATASET == \"MODU21\":\n",
    "    TRAIN_FILE = \"./data/NXNE2102203310.converted\" #MODU21\n",
    "elif DATASET == \"ETRI\":\n",
    "    TRAIN_FILE = \"./data/etri.converted\" #ETRI15\n",
    "else:\n",
    "    print(\"Please set your DATASET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=0\n",
    "ID, FORM, LEMMA, UPOS, XPOS, FEATS, HEAD, DEPREL, DEPS, MISC = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(word):\n",
    "    return re.sub(r\"\\d\", \"0\", word).lower()\n",
    "\n",
    "\n",
    "def strong_normalize(word):\n",
    "    w = ftfy.fix_text(word.lower())\n",
    "    w = re.sub(r\".+@.+\", \"*EMAIL*\", w)\n",
    "    w = re.sub(r\"@\\w+\", \"*AT*\", w)\n",
    "    w = re.sub(r\"(https?://|www\\.).*\", \"*url*\", w)\n",
    "    w = re.sub(r\"([^\\d])\\1{2,}\", r\"\\1\\1\", w)\n",
    "    w = re.sub(r\"([^\\d][^\\d])\\1{2,}\", r\"\\1\\1\", w)\n",
    "    w = re.sub(r\"``\", '\"', w)\n",
    "    w = re.sub(r\"''\", '\"', w)\n",
    "    w = re.sub(r\"\\d\", \"0\", w)\n",
    "    return w\n",
    "\n",
    "\n",
    "def buildVocab(graphs, cutoff=1):\n",
    "    wordsCount = Counter()\n",
    "    charsCount = Counter()\n",
    "    uposCount = Counter()\n",
    "    xposCount = Counter()\n",
    "    relCount = Counter()\n",
    "    featCount = Counter()\n",
    "    langCount = Counter()\n",
    "\n",
    "    for graph in graphs:\n",
    "        wordsCount.update([node.norm for node in graph.nodes[1:]])\n",
    "        for node in graph.nodes[1:]:\n",
    "            charsCount.update(list(node.word))\n",
    "            featCount.update(node.feats_set)\n",
    "            #  charsCount.update(list(node.norm))\n",
    "        uposCount.update([node.upos for node in graph.nodes[1:]])\n",
    "        xposCount.update([node.xupos for node in graph.nodes[1:]])\n",
    "        relCount.update([rel for rel in graph.rels[1:]])\n",
    "        langCount.update([node.lang for node in graph.nodes[1:]])\n",
    "        \n",
    "\n",
    "    wordsCount = Counter({w: i for w, i in wordsCount.items() if i >= cutoff})\n",
    "    print(\"Vocab containing {} words\".format(len(wordsCount)))\n",
    "    print(\"Charset containing {} chars\".format(len(charsCount)))\n",
    "    print(\"UPOS containing {} tags\".format(len(uposCount)), uposCount)\n",
    "    #print(\"XPOS containing {} tags\".format(len(xposCount)), xposCount)\n",
    "    print(\"Rels containing {} tags\".format(len(relCount)), relCount)\n",
    "    print(\"Feats containing {} tags\".format(len(featCount)), featCount)\n",
    "    print(\"lang containing {} tags\".format(len(langCount)), langCount)\n",
    "\n",
    "    ret = {\n",
    "        \"vocab\": list(wordsCount.keys()),\n",
    "        \"wordfreq\": wordsCount,\n",
    "        \"charset\": list(charsCount.keys()),\n",
    "        \"charfreq\": charsCount,\n",
    "        \"upos\": list(uposCount.keys()),\n",
    "        \"xpos\": list(xposCount.keys()),\n",
    "        \"rels\": list(relCount.keys()),\n",
    "        \"feats\": list(featCount.keys()),\n",
    "        \"lang\": list(langCount.keys()),\n",
    "    }\n",
    "\n",
    "    return ret\n",
    "\n",
    "def shuffled_stream(data):\n",
    "    len_data = len(data)\n",
    "    while True:\n",
    "        for d in random.sample(data, len_data):\n",
    "            yield d\n",
    "\n",
    "def shuffled_balanced_stream(data):\n",
    "    for ds in zip(*[shuffled_stream(s) for s in data]):\n",
    "        ds = list(ds)\n",
    "        random.shuffle(ds)\n",
    "        for d in ds:\n",
    "            yield d\n",
    "            \n",
    "            \n",
    "def parse_dict(features):\n",
    "    if features is None or features == \"_\":\n",
    "        return {}\n",
    "\n",
    "    ret = {}\n",
    "    lst = features.split(\"|\")\n",
    "    for l in lst:\n",
    "        k, v = l.split(\"=\")\n",
    "        ret[k] = v\n",
    "    return ret\n",
    "\n",
    "\n",
    "def parse_features(features):\n",
    "    if features is None or features == \"_\":\n",
    "        return set()\n",
    "\n",
    "    return features.lower().split(\"|\")\n",
    "\n",
    "\n",
    "class Word:\n",
    "\n",
    "    def __init__(self, word, upos, lemma=None, xpos=None, feats=None, misc=None, lang=None):\n",
    "        self.word = word\n",
    "        self.norm = normalize(word) #strong_normalize(word)\n",
    "        self.lemma = lemma if lemma else \"_\"\n",
    "        self.upos = upos\n",
    "        self.xpos = xpos if xpos else \"_\"\n",
    "        self.xupos = self.upos + \"|\" + self.xpos\n",
    "        self.feats = feats if feats else \"_\"\n",
    "        self.feats_set = parse_features(self.feats)\n",
    "        self.misc = misc if misc else \"_\"\n",
    "        self.lang = lang if lang else \"_\"\n",
    "\n",
    "    def cleaned(self):\n",
    "        return Word(self.word, \"_\")\n",
    "\n",
    "    def clone(self):\n",
    "        return Word(self.word, self.upos, self.lemma, self.xpos, self.feats, self.misc)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}_{}\".format(self.word, self.upos)\n",
    "\n",
    "\n",
    "class DependencyGraph(object):\n",
    "\n",
    "    def __init__(self, words, tokens=None):\n",
    "        #  Token is a tuple (start, end, form)\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        self.nodes = np.array([Word(\"*root*\", \"*root*\")] + list(words))\n",
    "        self.tokens = tokens\n",
    "        self.heads = np.array([-1] * len(self.nodes))\n",
    "        self.rels = np.array([\"_\"] * len(self.nodes), dtype=object)\n",
    "\n",
    "    def __copy__(self):\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        result.nodes = self.nodes\n",
    "        result.tokens = self.tokens\n",
    "        result.heads = self.heads.copy()\n",
    "        result.rels = self.rels.copy()\n",
    "        return result\n",
    "\n",
    "    def cleaned(self, node_level=True):\n",
    "        if node_level:\n",
    "            return DependencyGraph([node.cleaned() for node in self.nodes[1:]], self.tokens)\n",
    "        else:\n",
    "            return DependencyGraph([node.clone() for node in self.nodes[1:]], self.tokens)\n",
    "\n",
    "    def attach(self, head, tail, rel):\n",
    "        self.heads[tail] = head\n",
    "        self.rels[tail] = rel\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([\"{} ->({})  {} ({})\".format(str(self.nodes[i]), self.rels[i], self.heads[i], self.nodes[self.heads[i]]) for i in range(len(self.nodes))])\n",
    "\n",
    "\n",
    "def read_conll(filename, lang_code=None):\n",
    "    \n",
    "    print(\"read_conll with\", lang_code)\n",
    "    def get_word(columns):\n",
    "        return Word(columns[FORM], columns[UPOS], lemma=columns[LEMMA], xpos=columns[XPOS], feats=columns[FEATS], misc=columns[MISC], lang=lang_code)\n",
    "\n",
    "    def get_graph(graphs, words, tokens, edges):\n",
    "        graph = DependencyGraph(words, tokens)\n",
    "        for (h, d, r) in edges:\n",
    "            graph.attach(h, d, r)\n",
    "        graphs.append(graph)\n",
    "\n",
    "    file = open(filename, \"r\", encoding=\"UTF-8\")\n",
    "\n",
    "    graphs = []\n",
    "    words = []\n",
    "    tokens = []\n",
    "    edges = []\n",
    "\n",
    "    num_sent = 0\n",
    "    sentence_start = False\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            if len(words) > 0:\n",
    "                get_graph(graphs, words, tokens, edges)\n",
    "                words, tokens, edges = [], [], []\n",
    "            break\n",
    "        line = line.rstrip(\"\\r\\n\")\n",
    "\n",
    "        # Handle sentence start boundaries\n",
    "        if not sentence_start:\n",
    "            # Skip comments\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            # Start a new sentence\n",
    "            sentence_start = True\n",
    "        if not line:\n",
    "            sentence_start = False\n",
    "            if len(words) > 0:\n",
    "                if (len(words) < 250):\n",
    "                    get_graph(graphs, words, tokens, edges)\n",
    "                words, tokens, edges = [], [], []\n",
    "                num_sent += 1\n",
    "            continue\n",
    "\n",
    "        # Read next token/word\n",
    "        columns = line.split(\"\\t\")\n",
    "\n",
    "        # Skip empty nodes\n",
    "        if \".\" in columns[ID]:\n",
    "            continue\n",
    "\n",
    "        # Handle multi-word tokens to save word(s)\n",
    "        if \"-\" in columns[ID]:\n",
    "            start, end = map(int, columns[ID].split(\"-\"))\n",
    "            tokens.append((start, end + 1, columns[FORM]))\n",
    "\n",
    "            for _ in range(start, end + 1):\n",
    "                word_line = file.readline().rstrip(\"\\r\\n\")\n",
    "                word_columns = word_line.split(\"\\t\")\n",
    "                words.append(get_word(word_columns))\n",
    "                if word_columns[HEAD].isdigit():\n",
    "                    head = int(word_columns[HEAD])\n",
    "                else:\n",
    "                    head = -1\n",
    "                edges.append((head, int(word_columns[ID]), word_columns[DEPREL].split(\":\")[0]))\n",
    "        # Basic tokens/words\n",
    "        else:\n",
    "            words.append(get_word(columns))\n",
    "            if columns[HEAD].isdigit():\n",
    "                head = int(columns[HEAD])\n",
    "            else:\n",
    "                head = -1\n",
    "            edges.append((head, int(columns[ID]), columns[DEPREL].split(\":\")[0]))\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loader\n",
    "class CoNLLDataset:\n",
    "    def __init__(self, graphs, tokenizer, max_len, fullvocab=None):\n",
    "        self.conll_graphs = graphs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self._fullvocab = fullvocab if fullvocab else buildVocab(self.conll_graphs, cutoff=1)\n",
    "            \n",
    "        self._upos = {p: i for i, p in enumerate(self._fullvocab[\"upos\"])}\n",
    "        self._iupos = self._fullvocab[\"upos\"]\n",
    "        self._xpos = {p: i for i, p in enumerate(self._fullvocab[\"xpos\"])}\n",
    "        self._ixpos = self._fullvocab[\"xpos\"]\n",
    "        self._vocab = {w: i+3 for i, w in enumerate(self._fullvocab[\"vocab\"])}\n",
    "        self._wordfreq = self._fullvocab[\"wordfreq\"]\n",
    "        self._charset = {c: i+3 for i, c in enumerate(self._fullvocab[\"charset\"])}\n",
    "        self._charfreq = self._fullvocab[\"charfreq\"]\n",
    "        self._rels = {r: i for i, r in enumerate(self._fullvocab[\"rels\"])}\n",
    "        self._irels = self._fullvocab[\"rels\"]\n",
    "        self._feats = {f: i for i, f in enumerate(self._fullvocab[\"feats\"])}\n",
    "        self._langs = {r: i+2 for i, r in enumerate(self._fullvocab[\"lang\"])}\n",
    "        self._ilangs = self._fullvocab[\"lang\"]\n",
    "        \n",
    "        #self._posRels = {r: i for i, r in enumerate(self._fullvocab[\"posRel\"])}\n",
    "        #self._iposRels = self._fullvocab[\"posRel\"]\n",
    "        \n",
    "        self._vocab['*pad*'] = 0\n",
    "        self._charset['*pad*'] = 0\n",
    "        self._langs['*pad*'] = 0\n",
    "        \n",
    "        self._vocab['*root*'] = 1\n",
    "        self._charset['*whitespace*'] = 1\n",
    "        \n",
    "        self._vocab['*unknown*'] = 2\n",
    "        self._charset['*unknown*'] = 2\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.conll_graphs)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        graph = self.conll_graphs[item]\n",
    "        word_list = [node.word for node in graph.nodes]\n",
    "        upos_list = [node.upos for node in graph.nodes]\n",
    "        feat_list = [node.feats for node in graph.nodes]\n",
    "        \n",
    "        encoded = self.tokenizer.encode_plus(' '.join(word_list[1:]),\n",
    "                                             None,\n",
    "                                             add_special_tokens=True,\n",
    "                                             max_length = self.max_len,\n",
    "                                             truncation=True,\n",
    "                                             pad_to_max_length = True)\n",
    "        \n",
    "        ids, mask = encoded['input_ids'], encoded['attention_mask']\n",
    "        \n",
    "        bpe_head_mask = [0]; upos_ids = [-1]; feat_ids = [-1] # --> CLS token\n",
    "        \n",
    "        for word, upos, feat in zip(word_list[1:], upos_list[1:], feat_list[1:]):\n",
    "            bpe_len = len(self.tokenizer.tokenize(word))\n",
    "            head_mask = [1] + [0]*(bpe_len-1)\n",
    "            bpe_head_mask.extend(head_mask)\n",
    "            upos_mask = [self._upos.get(upos)] + [-1]*(bpe_len-1)\n",
    "            upos_ids.extend(upos_mask)\n",
    "            feat_mask = [self._feats.get(feat.lower(), 2)] + [-1]*(bpe_len-1)\n",
    "            feat_ids.extend(feat_mask)\n",
    "            \n",
    "            #print(\"head_mask\", head_mask)\n",
    "        \n",
    "        bpe_head_mask.append(0); upos_ids.append(-1); feat_ids.append(-1) # --> END token\n",
    "        bpe_head_mask.extend([0] * (self.max_len - len(bpe_head_mask))) ## --> padding by max_len\n",
    "        upos_ids.extend([-1] * (self.max_len - len(upos_ids))) ## --> padding by max_len\n",
    "        feat_ids.extend([-1] * (self.max_len - len(feat_ids))) ## --> padding by max_len\n",
    "        \n",
    "        return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'bpe_head_mask': torch.tensor(bpe_head_mask, dtype=torch.long),\n",
    "                'upos_ids': torch.tensor(upos_ids, dtype=torch.long),\n",
    "                'feat_ids': torch.tensor(feat_ids, dtype=torch.long)\n",
    "               }\n",
    "    \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(total_pred, total_targ, noNER_idx):\n",
    "    \n",
    "    p = 0 # (retrived SB and real SB) / retrived SB  # The percentage of (the number of correct predictions) / (the number of predction that system predicts as B-SENT)\n",
    "    r = 0\n",
    "    f1= 0\n",
    "    \n",
    "    np_total_pred = np.array(total_pred)\n",
    "    np_total_tag = np.array(total_targ)\n",
    "    \n",
    "    #Get noPad\n",
    "    incidence_nopad = np.where(np_total_tag != -1) ## eliminate paddings\n",
    "    np_total_pred_nopad = np_total_pred[incidence_nopad]\n",
    "    np_total_tag_nopad = np_total_tag[incidence_nopad]\n",
    "    \n",
    "    \n",
    "    #precision\n",
    "    incidence_nopad_sb = np.where(np_total_pred_nopad != noNER_idx)\n",
    "    np_total_pred_nopad_sb = np_total_pred_nopad[incidence_nopad_sb]\n",
    "    np_total_tag_nopad_sb = np_total_tag_nopad[incidence_nopad_sb]\n",
    "    \n",
    "    count_active_tokens_p = len(np_total_pred_nopad_sb)\n",
    "    count_correct_p = np.count_nonzero((np_total_pred_nopad_sb==np_total_tag_nopad_sb) == True)\n",
    "    \n",
    "    '''\n",
    "    np_total_pred_incid = np_total_pred[incidence_p]\n",
    "    print(\"np_total_pred_incid\", np_total_pred_incid)\n",
    "    ids_sb_pred_p = np.where(np_total_pred_incid==1)\n",
    "    np_total_pred_p = np_total_pred_incid[ids_sb_pred_p]\n",
    "    np_total_tag_p = np_total_tag[ids_sb_pred_p]\n",
    "    \n",
    "    print(\"ids_sb_pred_p\", ids_sb_pred_p)\n",
    "    print(\"np_total_pred_p\", np_total_pred_p)\n",
    "    print(\"np_total_tag_p\", np_total_tag_p)\n",
    "    \n",
    "    count_active_tokens_p = len(np_total_pred_p)\n",
    "    count_correct_p = np.count_nonzero((np_total_pred_p==np_total_tag_p) == True)\n",
    "    '''\n",
    "    \n",
    "    print(\"count_correct_p\", count_correct_p)\n",
    "    print(\"count_active_tokens_p\", count_active_tokens_p)\n",
    "    \n",
    "    p = count_correct_p/count_active_tokens_p\n",
    "    print(\"precision:\", p)\n",
    "\n",
    "    \n",
    "    #recall\n",
    "    ids_sb_pred_r = np.where(np_total_tag_nopad != noNER_idx)\n",
    "    np_total_pred_r = np_total_pred_nopad[ids_sb_pred_r]\n",
    "    np_total_tag_r = np_total_tag_nopad[ids_sb_pred_r]\n",
    "    \n",
    "    #print(\"ids_sb_pred_r\", ids_sb_pred_r)\n",
    "    #print(\"np_total_pred_r\", np_total_pred_r)\n",
    "    #print(\"np_total_tag_r\", np_total_tag_r)\n",
    "    \n",
    "    count_active_tokens_r = len(np_total_pred_r)\n",
    "    count_correct_r = np.count_nonzero((np_total_pred_r==np_total_tag_r) == True)\n",
    "    \n",
    "    print(\"count_active_tokens_r\", count_active_tokens_r)\n",
    "    print(\"count_correct_r\", count_correct_r)\n",
    "    \n",
    "    r = count_correct_r/count_active_tokens_r\n",
    "    print(\"recall:\", r)\n",
    "    \n",
    "    \n",
    "    #F1\n",
    "    #f1 = 2*(p*r) / (p+r)\n",
    "    print(\"F1:\", f1)\n",
    "    \n",
    "    #count_active_tokens_recall = np.count_nonzero(np.array(total_targ) > -1)\n",
    "    #print(\"count_active_tokens_recall\", count_active_tokens_recall)\n",
    "    #count_active_tokens_precision = np.count_nonzero(np.array(total_targ) > -1)\n",
    "    \n",
    "    #count_correct = np.count_nonzero((np.array(total_pred)==np.array(total_targ)) == True)\n",
    "    #print(\"count_correct\",count_correct)\n",
    "    #print(\"ACCURACY:\", count_correct/count_active_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaEncoder(nn.Module):\n",
    "    def __init__(self, num_upos, num_feat):\n",
    "        super(XLMRobertaEncoder, self).__init__()\n",
    "        self.xlm_roberta = transformers.XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "        self.linear = nn.Linear(768, num_upos)\n",
    "        \n",
    "        self.f_dropout = nn.Dropout(0.33)\n",
    "        self.f_linear = nn.Linear(768, num_feat)\n",
    "            \n",
    "    def forward(self, ids, mask):\n",
    "        o1, o2 = self.xlm_roberta(ids, mask)\n",
    "        \n",
    "        #apool = torch.mean(o1, 1)\n",
    "        #mpool, _ = torch.max(o1, 1)\n",
    "        #cat = torch.cat((apool, mpool), 1)\n",
    "        #bo = self.dropout(cat)\n",
    "        p_logits = self.linear(o1)        \n",
    "        f_logits = self.f_linear(o1)   \n",
    "        \n",
    "        return p_logits, f_logits\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_conll with ko\n",
      "read_conll with ko\n",
      "Vocab containing 63955 words\n",
      "Charset containing 2682 chars\n",
      "UPOS containing 15 tags Counter({'NOUN': 692927, 'PRT': 524276, 'ADP': 371881, 'PUNCT': 212483, 'VERB': 211887, 'PROPN': 59151, 'ADV': 44178, 'NUM': 44104, 'ADJ': 31644, 'X': 24058, 'DET': 20618, 'PRON': 16305, 'SYM': 10518, 'CCONJ': 3037, 'INTJ': 433})\n",
      "Rels containing 1 tags Counter({'_': 2267500})\n",
      "Feats containing 294 tags Counter({'o': 1957476, 'b-ps_name': 22275, 'b-cv_occupation': 10342, 'i-dt_duration': 9290, 'b-ogg_economy': 9194, 'i-dt_others': 9148, 'i-qt_count': 8247, 'b-lcp_country': 8235, 'b-cv_position': 7529, 'b-qt_count': 6670, 'b-dt_year': 6555, 'b-tmm_disease': 6259, 'i-qt_percentage': 5971, 'i-afa_video': 5934, 'b-tr_science': 5148, 'b-afa_video': 5052, 'i-qt_man_count': 4937, 'b-tmi_hw': 4925, 'i-ps_name': 4893, 'i-qt_order': 4830, 'i-qt_price': 4609, 'b-dt_duration': 4479, 'i-tr_science': 4262, 'i-dt_year': 4167, 'b-am_part': 4138, 'b-qt_order': 3855, 'b-tm_cell_tissue_organ': 3671, 'b-ogg_politics': 3611, 'i-afa_document': 3494, 'b-dt_others': 3330, 'b-ps_character': 3202, 'b-qt_man_count': 3185, 'b-qt_percentage': 3077, 'b-cv_relation': 3043, 'b-tmi_service': 3031, 'i-ev_others': 2913, 'i-tmm_disease': 2660, 'b-afw_other_products': 2411, 'b-dt_day': 2402, 'b-cv_art': 2303, 'i-dt_day': 2298, 'i-afw_other_products': 2208, 'i-qt_age': 2157, 'i-ti_duration': 2136, 'i-ev_festival': 2121, 'i-afa_music': 1984, 'b-mt_chemical': 1984, 'b-qt_age': 1974, 'i-ogg_economy': 1948, 'b-ogg_education': 1811, 'b-lcp_city': 1797, 'b-qt_price': 1776, 'b-ev_others': 1618, 'b-afa_document': 1614, 'b-ev_festival': 1604, 'b-ogg_medicine': 1446, 'b-tr_medicine': 1422, 'b-ogg_art': 1417, 'b-af_transport': 1371, 'b-ti_duration': 1356, 'i-tmi_hw': 1304, 'i-qt_others': 1302, 'i-dt_month': 1279, 'i-tr_medicine': 1251, 'i-afa_performance': 1235, 'b-ogg_others': 1219, 'b-afa_music': 1204, 'b-lcp_capitalcity': 1196, 'b-lc_others': 1190, 'b-lcp_county': 1174, 'i-tmi_service': 1172, 'i-ogg_politics': 1088, 'i-cv_occupation': 1080, 'i-qt_length': 987, 'b-dt_month': 950, 'b-lcg_continent': 916, 'b-cv_food': 906, 'i-ogg_art': 882, 'i-cv_art': 866, 'b-tmm_drug': 855, 'i-tm_cell_tissue_organ': 852, 'b-tm_direction': 851, 'b-afa_performance': 841, 'b-lcp_province': 822, 'b-cv_prize': 822, 'i-cv_prize': 816, 'i-cv_position': 790, 'b-ogg_media': 777, 'i-ogg_others': 776, 'b-tmi_sw': 773, 'b-qt_others': 766, 'b-af_building': 721, 'b-fd_medicine': 714, 'i-ti_others': 703, 'i-cv_law': 700, 'b-am_mammalia': 698, 'b-cv_clothing': 646, 'i-cv_culture': 591, 'i-lc_others': 577, 'b-cv_tribe': 572, 'b-tm_color': 565, 'b-cv_law': 558, 'i-tmi_project': 550, 'i-mt_chemical': 524, 'b-qt_length': 504, 'b-lc_space': 483, 'b-af_musical_instrument': 479, 'i-ti_hour': 452, 'i-tmm_drug': 445, 'b-dt_season': 441, 'b-cv_language': 434, 'i-afa_art_craft': 426, 'i-ev_activity': 418, 'i-qt_weight': 389, 'i-tmi_sw': 387, 'i-ps_character': 383, 'i-ogg_medicine': 367, 'i-af_building': 365, 'b-cv_drink': 358, 'i-fd_medicine': 351, 'b-tr_social_science': 347, 'b-am_others': 345, 'b-fd_science': 345, 'b-am_insect': 315, 'b-cv_sports': 307, 'b-tmig_genre': 303, 'i-cv_policy': 302, 'b-fd_humanities': 283, 'b-ogg_science': 279, 'b-tmi_project': 269, 'b-cv_policy': 252, 'i-ev_war_revolution': 252, 'b-afa_art_craft': 249, 'i-ogg_education': 245, 'b-ogg_military': 245, 'b-ti_hour': 243, 'i-af_transport': 237, 'i-tmig_genre': 235, 'b-ev_sports': 232, 'b-cv_culture': 227, 'i-qt_size': 224, 'b-am_type': 220, 'b-ti_others': 216, 'i-ev_sports': 204, 'b-pt_part': 196, 'b-qt_weight': 196, 'b-pt_grass': 195, 'b-am_bird': 193, 'i-am_part': 193, 'b-am_fish': 192, 'b-mt_element': 191, 'b-dt_dynasty': 185, 'b-ogg_sports': 177, 'i-ogg_media': 164, 'b-ev_activity': 161, 'i-cv_food': 149, 'b-ev_war_revolution': 146, 'i-ogg_science': 142, 'b-af_cultural_asset': 140, 'b-af_road': 139, 'i-tmi_model': 137, 'b-tr_art': 137, 'i-cv_relation': 136, 'b-pt_fruit': 135, 'i-lcp_country': 132, 'b-af_weapon': 128, 'b-fd_social_science': 123, 'i-dt_dynasty': 123, 'b-qt_size': 116, 'i-qt_temperature': 107, 'b-mt_metal': 103, 'b-tm_shape': 103, 'i-fd_science': 102, 'b-ogg_religion': 102, 'i-dt_season': 101, 'b-lcg_river': 100, 'i-qt_speed': 96, 'i-cv_clothing': 90, 'i-ogg_sports': 90, 'b-cv_food_style': 90, 'i-qt_volume': 88, 'i-tr_social_science': 86, 'i-qt_album': 86, 'b-fd_art': 82, 'b-ogg_law': 80, 'i-tm_color': 79, 'b-lcg_mountain': 77, 'i-afw_service_products': 75, 'b-lcg_island': 74, 'b-qt_album': 72, 'b-pt_flower': 71, 'b-am_reptilia': 70, 'b-lcg_bay': 70, 'b-lcg_ocean': 69, 'i-cv_tribe': 69, 'b-pt_others': 69, 'b-mt_rock': 67, 'b-tr_humanities': 66, 'i-ogg_military': 65, 'i-af_road': 65, 'i-qt_phone': 64, 'i-lcp_province': 59, 'b-ogg_food': 57, 'i-tm_shape': 56, 'i-fd_humanities': 53, 'b-tmi_model': 52, 'i-pt_fruit': 52, 'i-fd_social_science': 48, 'b-qt_speed': 46, 'b-qt_temperature': 45, 'b-pt_tree': 45, 'i-qt_sports': 44, 'b-qt_volume': 43, 'b-afw_service_products': 41, 'b-dt_geoage': 41, 'b-pt_type': 40, 'b-cv_funds': 40, 'i-am_others': 39, 'i-cv_sports': 39, 'i-cv_funds': 39, 'i-dt_week': 38, 'b-dt_week': 37, 'i-tr_art': 37, 'i-ogg_law': 35, 'i-af_cultural_asset': 34, 'i-ogg_food': 34, 'i-lc_space': 33, 'i-lcp_city': 33, 'i-qt_channel': 31, 'i-lcp_county': 30, 'i-af_musical_instrument': 29, 'b-ogg_library': 28, 'i-dt_geoage': 28, 'b-qt_phone': 28, 'i-cv_drink': 28, 'b-ogg_hotel': 27, 'i-tr_humanities': 27, 'i-am_bird': 27, 'b-tr_others': 26, 'i-pt_type': 26, 'i-am_type': 26, 'i-fd_art': 24, 'i-tr_others': 24, 'b-qt_sports': 23, 'i-ogg_hotel': 21, 'i-mt_metal': 21, 'i-ti_minute': 20, 'i-tm_direction': 18, 'b-cv_building_type': 17, 'b-qt_channel': 17, 'b-tmi_site': 16, 'b-tm_sports': 16, 'b-cv_sports_position': 16, 'i-ogg_library': 15, 'i-tmi_site': 14, 'i-am_mammalia': 13, 'b-fd_others': 12, 'i-lcg_island': 11, 'b-ps_pet': 11, 'i-lcg_continent': 11, 'b-cv_sports_inst': 11, 'i-lcp_capitalcity': 10, 'b-cv_tax': 10, 'b-ti_minute': 10, 'i-tm_sports': 10, 'i-af_weapon': 9, 'i-lcg_mountain': 9, 'i-lcg_ocean': 9, 'i-ogg_religion': 9, 'b-qt_address': 8, 'i-am_fish': 8, 'i-fd_others': 8, 'i-pt_part': 6, 'i-cv_sports_position': 6, 'i-pt_grass': 6, 'i-qt_address': 5, 'i-am_reptilia': 5, 'i-lcg_river': 5, 'i-ti_second': 5, 'b-am_amphibia': 5, 'i-cv_language': 5, 'b-cv_currency': 4, 'i-tmi_email': 4, 'i-mt_element': 3, 'i-pt_flower': 3, 'b-ti_second': 3, 'i-cv_food_style': 3, 'i-lcg_bay': 3, 'i-cv_tax': 2, 'b-tmi_email': 2, 'i-pt_others': 2, 'i-am_insect': 1, 'b-tm_climate': 1, 'i-pt_tree': 1})\n",
      "lang containing 1 tags Counter({'ko': 2267500})\n"
     ]
    }
   ],
   "source": [
    "if VALID_FILE is not None:\n",
    "    train_graphs = read_conll(TRAIN_FILE, 'ko')\n",
    "    valid_graphs = read_conll(VALID_FILE, 'ko')\n",
    "else:\n",
    "    graphs = read_conll(TRAIN_FILE, 'ko')\n",
    "    if DATASET == \"KLUE\":\n",
    "        valid_graphs = graphs[9001:18000]\n",
    "        train_graphs = graphs[18001:]\n",
    "    elif DATASET == \"MODU21\":\n",
    "        valid_graphs = graphs[69485:]\n",
    "        train_graphs = graphs[:68400]\n",
    "    elif DATASET == \"MODU19\":\n",
    "        valid_graphs = graphs[69485:]\n",
    "        train_graphs = graphs[:68400]\n",
    "    elif DATASET == \"ETRI\":\n",
    "        valid_graphs = graphs[69485:]\n",
    "        train_graphs = graphs[:68400]\n",
    "    else:\n",
    "        print(\"Please set the dataset among [KLUE, MODU21, MODU19, ETRI, NAVER]\")\n",
    "\n",
    "train_dataset = CoNLLDataset(graphs=train_graphs, tokenizer=TOKENIZER, max_len=MAX_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, num_workers=4, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "valid_dataset = CoNLLDataset(graphs=valid_graphs, tokenizer=TOKENIZER, max_len=MAX_LEN, fullvocab=train_dataset._fullvocab)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, num_workers=4, batch_size=VALID_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78168"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_upos = len(train_dataset._upos)\n",
    "num_feat = len(train_dataset._feats)\n",
    "model = XLMRobertaEncoder(num_upos, num_feat)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "lr = 0.000005\n",
    "optimizer = AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(train_loader, model, optimizer, DEVICE, scheduler=None):\n",
    "    model.train()\n",
    "    \n",
    "    p_total_pred = []\n",
    "    p_total_targ = []\n",
    "    p_total_loss = []\n",
    "    \n",
    "    f_total_pred = []\n",
    "    f_total_targ = []\n",
    "    f_total_loss = []\n",
    "    \n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        p_logits, f_logits = model(batch['ids'].cuda(), batch['mask'].cuda())\n",
    "        \n",
    "        #UPOS\n",
    "        b,s,l = p_logits.size()\n",
    "        #print(p_logits.view(b*s,l), p_logits.view(b*s,l).size())\n",
    "        #print(batch['upos_ids'].cuda().view(b*s), batch['upos_ids'].cuda().view(b*s).size())\n",
    "        p_loss = loss_fn(p_logits.view(b*s,l), batch['upos_ids'].cuda().view(b*s))\n",
    "        p_total_loss.append(p_loss.item())\n",
    "        p_total_pred.extend(torch.argmax(p_logits.view(b*s,l), 1).cpu().tolist())\n",
    "        p_total_targ.extend(batch['upos_ids'].cuda().view(b*s).cpu().tolist())\n",
    "        \n",
    "        #FEAT\n",
    "        b,s,l = f_logits.size()\n",
    "        f_loss = loss_fn(f_logits.view(b*s,l), batch['feat_ids'].cuda().view(b*s))\n",
    "        f_total_loss.append(f_loss.item())\n",
    "        f_total_pred.extend(torch.argmax(f_logits.view(b*s,l), 1).cpu().tolist())\n",
    "        f_total_targ.extend(batch['feat_ids'].cuda().view(b*s).cpu().tolist())\n",
    "        \n",
    "        #loss = p_loss+f_loss\n",
    "        loss = f_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    count_active_tokens = np.count_nonzero(np.array(p_total_targ) > -1)\n",
    "    count_correct = np.count_nonzero((np.array(p_total_pred)==np.array(p_total_targ)) == True)\n",
    "    print(\"TRAINING POS ACCURACY:\", count_correct/count_active_tokens)\n",
    "    \n",
    "    count_active_tokens = np.count_nonzero(np.array(f_total_targ) > -1)\n",
    "    count_correct = np.count_nonzero((np.array(f_total_pred)==np.array(f_total_targ)) == True)\n",
    "    f1_score(f_total_pred, f_total_targ, train_dataset._feats.get('o', 2))\n",
    "    print(\"TRAINING FEAT ACCURACY:\", count_correct/count_active_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop_fn(dev_loader, model, DEVICE):\n",
    "    model.eval()\n",
    "    \n",
    "    p_total_pred = []\n",
    "    p_total_targ = []\n",
    "    p_total_loss = []\n",
    "    \n",
    "    f_total_pred = []\n",
    "    f_total_targ = []\n",
    "    f_total_loss = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(dev_loader), total=len(dev_loader)):\n",
    "\n",
    "            p_logits, f_logits = model(batch['ids'].cuda(), batch['mask'].cuda())\n",
    "\n",
    "            #UPOS\n",
    "            b,s,l = p_logits.size()\n",
    "            p_loss = loss_fn(p_logits.view(b*s,l), batch['upos_ids'].cuda().view(b*s))\n",
    "            p_total_loss.append(p_loss.item())\n",
    "            p_total_pred.extend(torch.argmax(p_logits.view(b*s,l), 1).cpu().tolist())\n",
    "            p_total_targ.extend(batch['upos_ids'].cuda().view(b*s).cpu().tolist())\n",
    "\n",
    "            #FEAT\n",
    "            b,s,l = f_logits.size()\n",
    "            f_loss = loss_fn(f_logits.view(b*s,l), batch['feat_ids'].cuda().view(b*s))\n",
    "            f_total_loss.append(f_loss.item())\n",
    "            f_total_pred.extend(torch.argmax(f_logits.view(b*s,l), 1).cpu().tolist())\n",
    "            f_total_targ.extend(batch['feat_ids'].cuda().view(b*s).cpu().tolist())\n",
    "\n",
    "            loss = p_loss+f_loss\n",
    "        \n",
    "    count_active_tokens = np.count_nonzero(np.array(p_total_targ) > -1)\n",
    "    count_correct = np.count_nonzero((np.array(p_total_pred)==np.array(p_total_targ)) == True)\n",
    "    print(\"VALIDATION POS ACCURACY:\", count_correct/count_active_tokens)\n",
    "    \n",
    "    count_active_tokens = np.count_nonzero(np.array(f_total_targ) > -1)\n",
    "    count_correct = np.count_nonzero((np.array(f_total_pred)==np.array(f_total_targ)) == True)\n",
    "    f1_score(f_total_pred, f_total_targ, train_dataset._feats.get('o', 2))\n",
    "    print(\"VALIDATION FEAT ACCURACY:\", count_correct/count_active_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset._feats.get('o'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1303 [00:00<?, ?it/s]\r  0%|          | 1/1303 [00:05<1:50:00,  5.07s/it]\r  0%|          | 2/1303 [00:06<1:00:38,  2.80s/it]\r  0%|          | 3/1303 [00:07<44:52,  2.07s/it]  \r  0%|          | 4/1303 [00:08<37:30,  1.73s/it]\r  0%|          | 5/1303 [00:09<33:24,  1.54s/it]\r  0%|          | 6/1303 [00:11<30:54,  1.43s/it]\r  1%|          | 7/1303 [00:12<29:19,  1.36s/it]\r  1%|          | 8/1303 [00:13<28:18,  1.31s/it]\r  1%|          | 9/1303 [00:14<27:37,  1.28s/it]\r  1%|          | 10/1303 [00:15<27:09,  1.26s/it]\r  1%|          | 11/1303 [00:17<26:48,  1.24s/it]\r  1%|          | 12/1303 [00:18<26:35,  1.24s/it]\r  1%|          | 13/1303 [00:19<26:24,  1.23s/it]\r  1%|          | 14/1303 [00:20<26:19,  1.23s/it]\r  1%|          | 15/1303 [00:22<26:14,  1.22s/it]\r  1%|          | 16/1303 [00:23<26:10,  1.22s/it]\r  1%|▏         | 17/1303 [00:24<26:04,  1.22s/it]\r  1%|▏         | 18/1303 [00:25<25:59,  1.21s/it]\r  1%|▏         | 19/1303 [00:26<25:54,  1.21s/it]\r  2%|▏         | 20/1303 [00:28<25:50,  1.21s/it]\r  2%|▏         | 21/1303 [00:29<25:51,  1.21s/it]\r  2%|▏         | 22/1303 [00:30<25:54,  1.21s/it]\r  2%|▏         | 23/1303 [00:31<25:50,  1.21s/it]\r  2%|▏         | 24/1303 [00:32<25:48,  1.21s/it]\r  2%|▏         | 25/1303 [00:34<25:49,  1.21s/it]\r  2%|▏         | 26/1303 [00:35<25:47,  1.21s/it]\r  2%|▏         | 27/1303 [00:36<25:45,  1.21s/it]\r  2%|▏         | 28/1303 [00:37<25:43,  1.21s/it]\r  2%|▏         | 29/1303 [00:38<25:44,  1.21s/it]\r  2%|▏         | 30/1303 [00:40<25:42,  1.21s/it]\r  2%|▏         | 31/1303 [00:41<25:40,  1.21s/it]\r  2%|▏         | 32/1303 [00:42<25:39,  1.21s/it]\r  3%|▎         | 33/1303 [00:43<25:38,  1.21s/it]\r  3%|▎         | 34/1303 [00:45<25:37,  1.21s/it]\r  3%|▎         | 35/1303 [00:46<25:36,  1.21s/it]\r  3%|▎         | 36/1303 [00:47<25:34,  1.21s/it]\r  3%|▎         | 37/1303 [00:48<25:34,  1.21s/it]\r  3%|▎         | 38/1303 [00:49<25:31,  1.21s/it]\r  3%|▎         | 39/1303 [00:51<25:30,  1.21s/it]\r  3%|▎         | 40/1303 [00:52<25:29,  1.21s/it]\r  3%|▎         | 41/1303 [00:53<25:28,  1.21s/it]\r  3%|▎         | 42/1303 [00:54<25:27,  1.21s/it]\r  3%|▎         | 43/1303 [00:55<25:25,  1.21s/it]\r  3%|▎         | 44/1303 [00:57<25:24,  1.21s/it]\r  3%|▎         | 45/1303 [00:58<25:23,  1.21s/it]\r  4%|▎         | 46/1303 [00:59<25:21,  1.21s/it]\r  4%|▎         | 47/1303 [01:00<25:20,  1.21s/it]\r  4%|▎         | 48/1303 [01:01<25:20,  1.21s/it]\r  4%|▍         | 49/1303 [01:03<25:22,  1.21s/it]\r  4%|▍         | 50/1303 [01:04<25:20,  1.21s/it]\r  4%|▍         | 51/1303 [01:05<25:19,  1.21s/it]\r  4%|▍         | 52/1303 [01:06<25:16,  1.21s/it]\r  4%|▍         | 53/1303 [01:08<25:15,  1.21s/it]\r  4%|▍         | 54/1303 [01:09<25:15,  1.21s/it]\r  4%|▍         | 55/1303 [01:10<25:14,  1.21s/it]\r  4%|▍         | 56/1303 [01:11<25:21,  1.22s/it]\r  4%|▍         | 57/1303 [01:12<25:16,  1.22s/it]\r  4%|▍         | 58/1303 [01:14<25:15,  1.22s/it]\r  5%|▍         | 59/1303 [01:15<25:13,  1.22s/it]\r  5%|▍         | 60/1303 [01:16<25:11,  1.22s/it]\r  5%|▍         | 61/1303 [01:17<25:09,  1.22s/it]\r  5%|▍         | 62/1303 [01:19<25:07,  1.22s/it]\r  5%|▍         | 63/1303 [01:20<25:05,  1.21s/it]\r  5%|▍         | 64/1303 [01:21<25:09,  1.22s/it]\r  5%|▍         | 65/1303 [01:22<25:05,  1.22s/it]\r  5%|▌         | 66/1303 [01:23<25:03,  1.22s/it]\r  5%|▌         | 67/1303 [01:25<25:01,  1.21s/it]\r  5%|▌         | 68/1303 [01:26<25:01,  1.22s/it]\r  5%|▌         | 69/1303 [01:27<25:00,  1.22s/it]\r  5%|▌         | 70/1303 [01:28<24:59,  1.22s/it]\r  5%|▌         | 71/1303 [01:29<24:56,  1.21s/it]\r  6%|▌         | 72/1303 [01:31<24:54,  1.21s/it]\r  6%|▌         | 73/1303 [01:32<24:55,  1.22s/it]\r  6%|▌         | 74/1303 [01:33<24:53,  1.22s/it]\r  6%|▌         | 75/1303 [01:34<24:52,  1.22s/it]\r  6%|▌         | 76/1303 [01:36<24:51,  1.22s/it]\r  6%|▌         | 77/1303 [01:37<24:49,  1.22s/it]\r  6%|▌         | 78/1303 [01:38<24:50,  1.22s/it]\r  6%|▌         | 79/1303 [01:39<24:49,  1.22s/it]\r  6%|▌         | 80/1303 [01:40<24:46,  1.22s/it]\r  6%|▌         | 81/1303 [01:42<24:45,  1.22s/it]\r  6%|▋         | 82/1303 [01:43<24:44,  1.22s/it]\r  6%|▋         | 83/1303 [01:44<24:51,  1.22s/it]\r  6%|▋         | 84/1303 [01:45<24:46,  1.22s/it]\r  7%|▋         | 85/1303 [01:46<24:43,  1.22s/it]\r  7%|▋         | 86/1303 [01:48<24:41,  1.22s/it]\r  7%|▋         | 87/1303 [01:49<24:39,  1.22s/it]\r  7%|▋         | 88/1303 [01:50<24:37,  1.22s/it]\r  7%|▋         | 89/1303 [01:51<24:35,  1.22s/it]\r  7%|▋         | 90/1303 [01:53<24:34,  1.22s/it]\r  7%|▋         | 91/1303 [01:54<24:33,  1.22s/it]\r  7%|▋         | 92/1303 [01:55<24:33,  1.22s/it]\r  7%|▋         | 93/1303 [01:56<24:32,  1.22s/it]\r  7%|▋         | 94/1303 [01:57<24:29,  1.22s/it]\r  7%|▋         | 95/1303 [01:59<24:29,  1.22s/it]\r  7%|▋         | 96/1303 [02:00<24:26,  1.21s/it]\r  7%|▋         | 97/1303 [02:01<24:26,  1.22s/it]\r  8%|▊         | 98/1303 [02:02<24:24,  1.21s/it]\r  8%|▊         | 99/1303 [02:04<24:20,  1.21s/it]\r  8%|▊         | 100/1303 [02:05<24:19,  1.21s/it]\r  8%|▊         | 101/1303 [02:06<24:19,  1.21s/it]\r  8%|▊         | 102/1303 [02:07<24:18,  1.21s/it]\r  8%|▊         | 103/1303 [02:08<24:18,  1.22s/it]\r  8%|▊         | 104/1303 [02:10<24:15,  1.21s/it]\r  8%|▊         | 105/1303 [02:11<24:15,  1.21s/it]\r  8%|▊         | 106/1303 [02:12<24:14,  1.22s/it]\r  8%|▊         | 107/1303 [02:13<24:13,  1.22s/it]\r  8%|▊         | 108/1303 [02:14<24:11,  1.21s/it]\r  8%|▊         | 109/1303 [02:16<24:09,  1.21s/it]\r  8%|▊         | 110/1303 [02:17<24:08,  1.21s/it]\r  9%|▊         | 111/1303 [02:18<24:06,  1.21s/it]\r  9%|▊         | 112/1303 [02:19<24:06,  1.21s/it]\r  9%|▊         | 113/1303 [02:21<24:05,  1.21s/it]\r  9%|▊         | 114/1303 [02:22<24:04,  1.22s/it]\r  9%|▉         | 115/1303 [02:23<24:04,  1.22s/it]\r  9%|▉         | 116/1303 [02:24<24:03,  1.22s/it]\r  9%|▉         | 117/1303 [02:25<24:01,  1.22s/it]\r  9%|▉         | 118/1303 [02:27<24:02,  1.22s/it]\r  9%|▉         | 119/1303 [02:28<24:00,  1.22s/it]\r  9%|▉         | 120/1303 [02:29<23:59,  1.22s/it]\r  9%|▉         | 121/1303 [02:30<23:57,  1.22s/it]\r  9%|▉         | 122/1303 [02:31<23:57,  1.22s/it]\r  9%|▉         | 123/1303 [02:33<23:56,  1.22s/it]\r 10%|▉         | 124/1303 [02:34<23:54,  1.22s/it]\r 10%|▉         | 125/1303 [02:35<23:54,  1.22s/it]\r 10%|▉         | 126/1303 [02:36<23:53,  1.22s/it]\r 10%|▉         | 127/1303 [02:38<23:50,  1.22s/it]\r 10%|▉         | 128/1303 [02:39<23:48,  1.22s/it]\r 10%|▉         | 129/1303 [02:40<23:47,  1.22s/it]\r 10%|▉         | 130/1303 [02:41<23:45,  1.22s/it]\r 10%|█         | 131/1303 [02:42<23:44,  1.22s/it]\r 10%|█         | 132/1303 [02:44<23:44,  1.22s/it]\r 10%|█         | 133/1303 [02:45<23:44,  1.22s/it]\r 10%|█         | 134/1303 [02:46<23:42,  1.22s/it]\r 10%|█         | 135/1303 [02:47<23:41,  1.22s/it]\r 10%|█         | 136/1303 [02:48<23:41,  1.22s/it]\r 11%|█         | 137/1303 [02:50<23:40,  1.22s/it]\r 11%|█         | 138/1303 [02:51<23:36,  1.22s/it]\r 11%|█         | 139/1303 [02:52<23:35,  1.22s/it]\r 11%|█         | 140/1303 [02:53<23:35,  1.22s/it]\r 11%|█         | 141/1303 [02:55<23:33,  1.22s/it]\r 11%|█         | 142/1303 [02:56<23:32,  1.22s/it]\r 11%|█         | 143/1303 [02:57<23:31,  1.22s/it]\r 11%|█         | 144/1303 [02:58<23:29,  1.22s/it]\r 11%|█         | 145/1303 [02:59<23:28,  1.22s/it]\r 11%|█         | 146/1303 [03:01<23:27,  1.22s/it]\r 11%|█▏        | 147/1303 [03:02<23:25,  1.22s/it]\r 11%|█▏        | 148/1303 [03:03<23:24,  1.22s/it]\r 11%|█▏        | 149/1303 [03:04<23:24,  1.22s/it]\r 12%|█▏        | 150/1303 [03:06<23:22,  1.22s/it]\r 12%|█▏        | 151/1303 [03:07<23:19,  1.22s/it]\r 12%|█▏        | 152/1303 [03:08<23:18,  1.22s/it]\r 12%|█▏        | 153/1303 [03:09<23:18,  1.22s/it]\r 12%|█▏        | 154/1303 [03:10<23:24,  1.22s/it]\r 12%|█▏        | 155/1303 [03:12<23:21,  1.22s/it]\r 12%|█▏        | 156/1303 [03:13<23:18,  1.22s/it]\r 12%|█▏        | 157/1303 [03:14<23:16,  1.22s/it]\r 12%|█▏        | 158/1303 [03:15<23:13,  1.22s/it]\r 12%|█▏        | 159/1303 [03:16<23:11,  1.22s/it]\r 12%|█▏        | 160/1303 [03:18<23:11,  1.22s/it]\r 12%|█▏        | 161/1303 [03:19<23:10,  1.22s/it]\r 12%|█▏        | 162/1303 [03:20<23:08,  1.22s/it]\r 13%|█▎        | 163/1303 [03:21<23:07,  1.22s/it]\r 13%|█▎        | 164/1303 [03:23<23:05,  1.22s/it]\r 13%|█▎        | 165/1303 [03:24<23:04,  1.22s/it]\r 13%|█▎        | 166/1303 [03:25<23:02,  1.22s/it]\r 13%|█▎        | 167/1303 [03:26<23:01,  1.22s/it]\r 13%|█▎        | 168/1303 [03:27<23:00,  1.22s/it]\r 13%|█▎        | 169/1303 [03:29<22:59,  1.22s/it]\r 13%|█▎        | 170/1303 [03:30<22:57,  1.22s/it]\r 13%|█▎        | 171/1303 [03:31<22:56,  1.22s/it]\r 13%|█▎        | 172/1303 [03:32<22:54,  1.22s/it]\r 13%|█▎        | 173/1303 [03:34<22:54,  1.22s/it]\r 13%|█▎        | 174/1303 [03:35<22:54,  1.22s/it]\r 13%|█▎        | 175/1303 [03:36<22:50,  1.22s/it]\r 14%|█▎        | 176/1303 [03:37<22:50,  1.22s/it]\r 14%|█▎        | 177/1303 [03:38<22:49,  1.22s/it]\r 14%|█▎        | 178/1303 [03:40<22:47,  1.22s/it]\r 14%|█▎        | 179/1303 [03:41<22:47,  1.22s/it]\r 14%|█▍        | 180/1303 [03:42<22:45,  1.22s/it]\r 14%|█▍        | 181/1303 [03:43<22:44,  1.22s/it]\r 14%|█▍        | 182/1303 [03:44<22:43,  1.22s/it]\r 14%|█▍        | 183/1303 [03:46<22:42,  1.22s/it]\r 14%|█▍        | 184/1303 [03:47<22:40,  1.22s/it]\r 14%|█▍        | 185/1303 [03:48<22:39,  1.22s/it]\r 14%|█▍        | 186/1303 [03:49<22:38,  1.22s/it]\r 14%|█▍        | 187/1303 [03:51<22:37,  1.22s/it]\r 14%|█▍        | 188/1303 [03:52<22:35,  1.22s/it]\r 15%|█▍        | 189/1303 [03:53<22:34,  1.22s/it]\r 15%|█▍        | 190/1303 [03:54<22:33,  1.22s/it]\r 15%|█▍        | 191/1303 [03:55<22:32,  1.22s/it]\r 15%|█▍        | 192/1303 [03:57<22:31,  1.22s/it]\r 15%|█▍        | 193/1303 [03:58<22:29,  1.22s/it]\r 15%|█▍        | 194/1303 [03:59<22:30,  1.22s/it]\r 15%|█▍        | 195/1303 [04:00<22:31,  1.22s/it]\r 15%|█▌        | 196/1303 [04:01<22:29,  1.22s/it]\r 15%|█▌        | 197/1303 [04:03<22:27,  1.22s/it]\r 15%|█▌        | 198/1303 [04:04<22:25,  1.22s/it]\r 15%|█▌        | 199/1303 [04:05<22:23,  1.22s/it]\r 15%|█▌        | 200/1303 [04:06<22:20,  1.22s/it]\r 15%|█▌        | 201/1303 [04:08<22:19,  1.22s/it]\r 16%|█▌        | 202/1303 [04:09<22:17,  1.21s/it]\r 16%|█▌        | 203/1303 [04:10<22:15,  1.21s/it]\r 16%|█▌        | 204/1303 [04:11<22:13,  1.21s/it]\r 16%|█▌        | 205/1303 [04:12<22:12,  1.21s/it]\r 16%|█▌        | 206/1303 [04:14<22:12,  1.21s/it]\r 16%|█▌        | 207/1303 [04:15<22:11,  1.22s/it]\r 16%|█▌        | 208/1303 [04:16<22:10,  1.22s/it]\r 16%|█▌        | 209/1303 [04:17<22:09,  1.22s/it]\r 16%|█▌        | 210/1303 [04:19<22:08,  1.22s/it]\r 16%|█▌        | 211/1303 [04:20<22:07,  1.22s/it]\r 16%|█▋        | 212/1303 [04:21<22:06,  1.22s/it]\r 16%|█▋        | 213/1303 [04:22<22:06,  1.22s/it]\r 16%|█▋        | 214/1303 [04:23<22:06,  1.22s/it]\r 17%|█▋        | 215/1303 [04:25<22:05,  1.22s/it]\r 17%|█▋        | 216/1303 [04:26<22:03,  1.22s/it]\r 17%|█▋        | 217/1303 [04:27<22:01,  1.22s/it]\r 17%|█▋        | 218/1303 [04:28<22:00,  1.22s/it]\r 17%|█▋        | 219/1303 [04:29<21:59,  1.22s/it]\r 17%|█▋        | 220/1303 [04:31<21:58,  1.22s/it]\r 17%|█▋        | 221/1303 [04:32<21:56,  1.22s/it]\r 17%|█▋        | 222/1303 [04:33<21:55,  1.22s/it]\r 17%|█▋        | 223/1303 [04:34<21:54,  1.22s/it]\r 17%|█▋        | 224/1303 [04:36<21:52,  1.22s/it]\r 17%|█▋        | 225/1303 [04:37<21:51,  1.22s/it]\r 17%|█▋        | 226/1303 [04:38<21:50,  1.22s/it]\r 17%|█▋        | 227/1303 [04:39<21:49,  1.22s/it]\r 17%|█▋        | 228/1303 [04:40<21:48,  1.22s/it]\r 18%|█▊        | 229/1303 [04:42<21:46,  1.22s/it]\r 18%|█▊        | 230/1303 [04:43<21:44,  1.22s/it]\r 18%|█▊        | 231/1303 [04:44<21:43,  1.22s/it]\r 18%|█▊        | 232/1303 [04:45<21:42,  1.22s/it]\r 18%|█▊        | 233/1303 [04:46<21:41,  1.22s/it]\r 18%|█▊        | 234/1303 [04:48<21:40,  1.22s/it]\r 18%|█▊        | 235/1303 [04:49<21:38,  1.22s/it]\r 18%|█▊        | 236/1303 [04:50<21:37,  1.22s/it]\r 18%|█▊        | 237/1303 [04:51<21:36,  1.22s/it]\r 18%|█▊        | 238/1303 [04:53<21:34,  1.22s/it]\r 18%|█▊        | 239/1303 [04:54<21:33,  1.22s/it]\r 18%|█▊        | 240/1303 [04:55<21:33,  1.22s/it]\r 18%|█▊        | 241/1303 [04:56<21:30,  1.22s/it]\r 19%|█▊        | 242/1303 [04:57<21:30,  1.22s/it]\r 19%|█▊        | 243/1303 [04:59<21:28,  1.22s/it]\r 19%|█▊        | 244/1303 [05:00<21:27,  1.22s/it]\r 19%|█▉        | 245/1303 [05:01<21:27,  1.22s/it]\r 19%|█▉        | 246/1303 [05:02<21:25,  1.22s/it]\r 19%|█▉        | 247/1303 [05:04<21:22,  1.21s/it]\r 19%|█▉        | 248/1303 [05:05<21:22,  1.22s/it]\r 19%|█▉        | 249/1303 [05:06<21:21,  1.22s/it]\r 19%|█▉        | 250/1303 [05:07<21:20,  1.22s/it]\r 19%|█▉        | 251/1303 [05:08<21:19,  1.22s/it]\r 19%|█▉        | 252/1303 [05:10<21:18,  1.22s/it]\r 19%|█▉        | 253/1303 [05:11<21:18,  1.22s/it]\r 19%|█▉        | 254/1303 [05:12<21:17,  1.22s/it]\r 20%|█▉        | 255/1303 [05:13<21:15,  1.22s/it]\r 20%|█▉        | 256/1303 [05:14<21:13,  1.22s/it]\r 20%|█▉        | 257/1303 [05:16<21:13,  1.22s/it]\r 20%|█▉        | 258/1303 [05:17<21:11,  1.22s/it]\r 20%|█▉        | 259/1303 [05:18<21:10,  1.22s/it]\r 20%|█▉        | 260/1303 [05:19<21:09,  1.22s/it]\r 20%|██        | 261/1303 [05:21<21:08,  1.22s/it]\r 20%|██        | 262/1303 [05:22<21:06,  1.22s/it]\r 20%|██        | 263/1303 [05:23<21:06,  1.22s/it]\r 20%|██        | 264/1303 [05:24<21:04,  1.22s/it]\r 20%|██        | 265/1303 [05:25<21:02,  1.22s/it]\r 20%|██        | 266/1303 [05:27<21:00,  1.22s/it]\r 20%|██        | 267/1303 [05:28<20:59,  1.22s/it]\r 21%|██        | 268/1303 [05:29<20:57,  1.22s/it]\r 21%|██        | 269/1303 [05:30<20:57,  1.22s/it]\r 21%|██        | 270/1303 [05:31<20:57,  1.22s/it]\r 21%|██        | 271/1303 [05:33<20:55,  1.22s/it]\r 21%|██        | 272/1303 [05:34<20:55,  1.22s/it]\r 21%|██        | 273/1303 [05:35<20:52,  1.22s/it]\r 21%|██        | 274/1303 [05:36<20:51,  1.22s/it]\r 21%|██        | 275/1303 [05:38<20:50,  1.22s/it]\r 21%|██        | 276/1303 [05:39<20:49,  1.22s/it]\r 21%|██▏       | 277/1303 [05:40<20:48,  1.22s/it]\r 21%|██▏       | 278/1303 [05:41<20:47,  1.22s/it]\r 21%|██▏       | 279/1303 [05:42<20:45,  1.22s/it]\r 21%|██▏       | 280/1303 [05:44<20:44,  1.22s/it]\r 22%|██▏       | 281/1303 [05:45<20:43,  1.22s/it]\r 22%|██▏       | 282/1303 [05:46<20:41,  1.22s/it]\r 22%|██▏       | 283/1303 [05:47<20:40,  1.22s/it]\r 22%|██▏       | 284/1303 [05:49<20:40,  1.22s/it]\r 22%|██▏       | 285/1303 [05:50<20:38,  1.22s/it]\r 22%|██▏       | 286/1303 [05:51<20:38,  1.22s/it]\r 22%|██▏       | 287/1303 [05:52<20:38,  1.22s/it]\r 22%|██▏       | 288/1303 [05:53<20:37,  1.22s/it]\r 22%|██▏       | 289/1303 [05:55<20:34,  1.22s/it]\r 22%|██▏       | 290/1303 [05:56<20:33,  1.22s/it]\r 22%|██▏       | 291/1303 [05:57<20:32,  1.22s/it]\r 22%|██▏       | 292/1303 [05:58<20:30,  1.22s/it]\r 22%|██▏       | 293/1303 [05:59<20:29,  1.22s/it]\r 23%|██▎       | 294/1303 [06:01<20:28,  1.22s/it]\r 23%|██▎       | 295/1303 [06:02<20:27,  1.22s/it]\r 23%|██▎       | 296/1303 [06:03<20:26,  1.22s/it]\r 23%|██▎       | 297/1303 [06:04<20:25,  1.22s/it]\r 23%|██▎       | 298/1303 [06:06<20:23,  1.22s/it]\r 23%|██▎       | 299/1303 [06:07<20:22,  1.22s/it]\r 23%|██▎       | 300/1303 [06:08<20:20,  1.22s/it]\r 23%|██▎       | 301/1303 [06:09<20:19,  1.22s/it]\r 23%|██▎       | 302/1303 [06:10<20:18,  1.22s/it]\r 23%|██▎       | 303/1303 [06:12<20:17,  1.22s/it]\r 23%|██▎       | 304/1303 [06:13<20:15,  1.22s/it]\r 23%|██▎       | 305/1303 [06:14<20:13,  1.22s/it]\r 23%|██▎       | 306/1303 [06:15<20:13,  1.22s/it]\r 24%|██▎       | 307/1303 [06:17<20:11,  1.22s/it]\r 24%|██▎       | 308/1303 [06:18<20:10,  1.22s/it]\r 24%|██▎       | 309/1303 [06:19<20:08,  1.22s/it]\r 24%|██▍       | 310/1303 [06:20<20:07,  1.22s/it]\r 24%|██▍       | 311/1303 [06:21<20:06,  1.22s/it]\r 24%|██▍       | 312/1303 [06:23<20:04,  1.22s/it]\r 24%|██▍       | 313/1303 [06:24<20:02,  1.21s/it]\r 24%|██▍       | 314/1303 [06:25<20:01,  1.21s/it]\r 24%|██▍       | 315/1303 [06:26<19:59,  1.21s/it]\r 24%|██▍       | 316/1303 [06:27<20:00,  1.22s/it]\r 24%|██▍       | 317/1303 [06:29<19:59,  1.22s/it]\r 24%|██▍       | 318/1303 [06:30<19:57,  1.22s/it]\r 24%|██▍       | 319/1303 [06:31<19:56,  1.22s/it]\r 25%|██▍       | 320/1303 [06:32<19:55,  1.22s/it]\r 25%|██▍       | 321/1303 [06:34<19:54,  1.22s/it]\r 25%|██▍       | 322/1303 [06:35<19:52,  1.22s/it]\r 25%|██▍       | 323/1303 [06:36<19:51,  1.22s/it]\r 25%|██▍       | 324/1303 [06:37<19:50,  1.22s/it]\r 25%|██▍       | 325/1303 [06:38<19:49,  1.22s/it]\r 25%|██▌       | 326/1303 [06:40<19:49,  1.22s/it]\r 25%|██▌       | 327/1303 [06:41<19:48,  1.22s/it]\r 25%|██▌       | 328/1303 [06:42<19:46,  1.22s/it]\r 25%|██▌       | 329/1303 [06:43<19:46,  1.22s/it]\r 25%|██▌       | 330/1303 [06:45<19:44,  1.22s/it]\r 25%|██▌       | 331/1303 [06:46<19:43,  1.22s/it]\r 25%|██▌       | 332/1303 [06:47<19:42,  1.22s/it]\r 26%|██▌       | 333/1303 [06:48<19:41,  1.22s/it]\r 26%|██▌       | 334/1303 [06:49<19:39,  1.22s/it]\r 26%|██▌       | 335/1303 [06:51<19:39,  1.22s/it]\r 26%|██▌       | 336/1303 [06:52<19:37,  1.22s/it]\r 26%|██▌       | 337/1303 [06:53<19:35,  1.22s/it]\r 26%|██▌       | 338/1303 [06:54<19:34,  1.22s/it]\r 26%|██▌       | 339/1303 [06:55<19:32,  1.22s/it]\r 26%|██▌       | 340/1303 [06:57<19:31,  1.22s/it]\r 26%|██▌       | 341/1303 [06:58<19:29,  1.22s/it]\r 26%|██▌       | 342/1303 [06:59<19:28,  1.22s/it]\r 26%|██▋       | 343/1303 [07:00<19:27,  1.22s/it]\r 26%|██▋       | 344/1303 [07:02<19:26,  1.22s/it]\r 26%|██▋       | 345/1303 [07:03<19:25,  1.22s/it]\r 27%|██▋       | 346/1303 [07:04<19:23,  1.22s/it]\r 27%|██▋       | 347/1303 [07:05<19:22,  1.22s/it]\r 27%|██▋       | 348/1303 [07:06<19:21,  1.22s/it]\r 27%|██▋       | 349/1303 [07:08<19:20,  1.22s/it]\r 27%|██▋       | 350/1303 [07:09<19:18,  1.22s/it]\r 27%|██▋       | 351/1303 [07:10<19:17,  1.22s/it]\r 27%|██▋       | 352/1303 [07:11<19:16,  1.22s/it]\r 27%|██▋       | 353/1303 [07:12<19:15,  1.22s/it]\r 27%|██▋       | 354/1303 [07:14<19:13,  1.22s/it]\r 27%|██▋       | 355/1303 [07:15<19:12,  1.22s/it]\r 27%|██▋       | 355/1303 [07:16<19:25,  1.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3953606/776203934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalid_loop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3953606/3239291393.py\u001b[0m in \u001b[0;36mtrain_loop_fn\u001b[0;34m(train_loader, model, optimizer, DEVICE, scheduler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#loss = p_loss+f_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NER/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/NER/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx in range(EPOCHS):\n",
    "    train_loop_fn(train_loader, model, optimizer, DEVICE)\n",
    "    valid_loop_fn(valid_loader, model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loop_fn(valid_loader, model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "df10c56ce450e567e3c41010846962ff5a955200bfed2d53d187c6446d09633f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
